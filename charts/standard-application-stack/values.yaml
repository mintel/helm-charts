# Default values for standard-application-stack.
# Declare variables to be passed into your templates.

# -- Global variables for us in all charts and sub charts
global:
  # -- Name of the application
  name: "example-app"
  # -- Team which "owns" the application
  owner: ""
  # -- Top level application each deployment is a part of
  partOf: ""
  # -- Additional labels to apply to all resources
  additionalLabels: {}
  # -- Kubernetes cluster domain
  clusterDomain: "127.0.0.1.nip.io"
  # -- Environment (local, dev, qa, prod)
  clusterEnv: "local"
  # -- Kubernetes cluster name
  clusterName: ""
  # -- Global variables relating to cloud provider
  cloudProvider:
    # -- AWS ACcount Id
    accountId: ""
  # -- Global variable definint RUNTIME_ENVIRONMENT
  runtimeEnvironment: kubernetes
  # -- Global dictionary of TLS secrets
  ingressTLSSecrets: {}
  terraform:
    # set to true as part of tf cloud migrations. When true, it stops standard-application-stack from creating AWS related external secrets and passes that responsibility to the terraform-cloud chart
    externalSecrets: false
    # set to true as part of tf cloud migrations. When true, standard-application-stack sets the service account eks annotation to match the new IAM roles created by the terraform-cloud chart
    irsa: false

# -- String to fully override mintel_common.fullname template
nameOverride: ""

# -- Minimum number of seconds before deployments are ready
minReadySeconds: 10

# -- Desired number of replicas for main deployment
replicas: 2

# -- Defines whether the deployment should be a statefulset or not
statefulset: false

# -- Explicitly stating that a single replica is required
# Should only be used if the image truly can't be run multiple times
# usually involving third party apps or prometheus exporters, etc
singleReplicaOnly: false

# -- Explicitly allow the number of replicas to equal 1
# Useful for backend event based services where we may only want
# a single replica but still want rolling updates etc
allowSingleReplica: false

# -- Docker image values
image:
  # -- Docker registry used to pull application image
  registry: ""
  # -- Docker repository
  repository: "test"
  # -- Container image tag
  tag: "auto-replaced"
  # -- Optional ImagePullPolicy
  # ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  pullPolicy: IfNotPresent

# -- Optional array of imagePullSecrets
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []

# -- Main container port for the application
# -- Set port to null to skip adding container Ports
port: 8000

# -- Optional list of extra container ports to configure
extraPorts: []
# extraPorts:
#   - name: ""
#     containerPort: 1234
#     protocol: "TCP"

# -- Optional command to the container
command:
  - /app/docker-entrypoint.sh

# -- Optional arguments to the container
args: []
# args:
#   - 'gunicorn'
#   - '--port=1234'

# -- Optional environment variables injected into the container
env: []
# env:
#   - name: APP_ENVIRONMENT
#     value: dev

# -- Optional environment variables injected into the container using envFrom (secrets/configmaps)
envFrom: []

# -- Handle autoscaling via https://keda.sh
# Creates a ScaledObject for the workload
# ref: https://keda.sh/docs/2.8/concepts/scaling-deployments/
autoscaling:
  enabled: false

  # Polling interval only impacts the time-to-activation (scaling from 0 to 1) but once scaled to 1
  # it's up to the HPA which polls KEDA.
  pollingInterval: 30  # min value allowed 10

  # The KEDA cooldownPeriod only applies when scaling to 0; scaling from 1 to N replicas is handled
  # by the Kubernetes Horizontal Pod Autoscaler.
  cooldownPeriod: 300  # min value allowed 60

  maxReplicaCount: 5  # max value allowed 10
  minReplicaCount: 2  # min value allowed 1

  # Enable zero replicas (sets idleReplicaCount=0)
  # ref: https://keda.sh/docs/2.8/concepts/scaling-deployments/#idlereplicacount
  # NOTE: Due to limitations in HPA controller the only supported value for this
  # property is 0, it will not work correctly otherwise (hence the boolean flag).
  enableZeroReplicas: false

  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    envSourceContainerName: ''

  # ref: https://keda.sh/docs/2.8/concepts/scaling-deployments/#fallback
  fallback:
    failureThreshold: 3
    replicas: 2

  # ref: https://keda.sh/docs/2.8/concepts/scaling-deployments/#advanced
  advanced: {}

  # ref: https://keda.sh/docs/2.8/concepts/scaling-deployments/#triggers
  # Includes helpers around cpu/memory (see `custom` field for upstream trigger support)
  triggers: {}
    # When using Utilization, the target value is the average of the resource metric across
    # all relevant pods, represented as a percentage of the requested value of the resource
    # for the pods.
    #
    # Only one of utilization or average-value can be specified.
    #
    # targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

    # When using AverageValue, the target value is the target value of the average of the
    # metric across all relevant pods (quantity).

    # targetCPUAverageValue: 80
    # targetMemoryAverageValue: 80

    # A list of custom triggers
    # ref: https://keda.sh/docs/2.8/scalers/
    #  custom:
    #  - type: 'aws-sqs-queue'
    #    metadata:
    #      queueURL: 'https://my-queue-url'
    #      queueLength: "20"
    #  - type: 'prometheus'
    #    metadata:
    #      metricName: 'http_requests_total',
    #      query: 'sum(rate(http_requests_total{service="podinfo-http"}[2m]))',
    #      threshold: '5',

# -- Optional name of PriorityClass to run pods with
priorityClassName: ""

# -- Additional annotations to apply to the pod
podAnnotations: {}

# -- Pod Security context for the container
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
podSecurityContext:
  runAsUser: 1000
#  fsGroup: 2000

# -- Pod Disruption Budget
# ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
podDisruptionBudget:
  enabled: true
  minAvailable: 50%
#  maxUnavailable: 50%

# -- Security context for the container
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
securityContext: {}
# securityContext:
#   allowPrivilegeEscalation: false
#   readOnlyRootFilesystem: true
#   capabilities:
#     drop: ["ALL"]
#   readOnlyRootFilesystem: true
#   runAsNonRoot: true
#   runAsUser: 1000

# -- Kubernetes svc configutarion
service:
  # -- Whether to create Service resource or not
  enabled: true
  # -- Kubernetes Service type
  type: ClusterIP
  # -- Annotations to add to service
  annotations: {}
  # -- Provide any additional labels which may be required.
  labels: {}

# -- ServiceAccount parameters
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccount:
  # -- Determine whether a Service Account should be created or it should reuse a exiting one.
  create: true
  # -- ServiceAccount to use. A name is generated using the mintel_common.fullname template if it is not set
  name: ""
  # -- Additional Service Account annotations
  annotations: {}
  # -- Configures IRSA for the Service Account
  irsa:
    # -- Determines whether service account is IRSA enabled
    enabled: false
    # -- Override for last component of role-arn, ie: accountid-clusterName-namespace-{nameOverride}
    nameOverride: ""
  # -- Whether to automount the service account token or not
  automountServiceAccountToken: true

  # -- Define list of Role's to create and bind to the service account
  # ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/
  roles: []
  #  - name: 'main'
  #    rules:
  #    - apiGroups: []
  #      resources: []
  #      verbs: []

  # -- Define list of ClusterRole's to create and bind to the service account
  # ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/
  clusterRoles: []
  #  - name: 'main'
  #    rules:
  #    - apiGroups: []
  #      resources: []
  #      verbs: []

# -- Configure extra options for liveness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
liveness:
  # -- Enable liveness probe
  enabled: true
  #  methodOverride:
  #    httpGet:
  #      # -- Request path for livenessProbe
  #      path: /healthz
  #      # -- Port for livenessProbe
  #      port: 8000
  #      # -- Scheme (HTTP or HTTPS)
  #      scheme: HTTP
  # -- Path to hit for liveness checks
  #  path: /healthz
  # -- Name of the port to use for liveness checks
  #  port: http
  # -- Scheme (HTTP or HTTPS)
  #  scheme: HTTP
  # -- Initial delay seconds for livenessProbe
  #  initialDelaySeconds: 25
  # -- Period seconds for livenessProbe (frequency)
  #  periodSeconds: 10
  # -- Timeout seconds for livenessProbe
  #  timeoutSeconds: 1
  # -- Failure threshold for livenessProbe
  #  failureThreshold: 2
  # -- Success threshold for livenessProbe
  #  successThreshold: 1
  # -- Configure startup probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes
  startup:
    # -- Failure threshold for startupProbe
    failureThreshold: 60
    # -- Perios seconds for startupProbe
    periodSeconds: 5

# -- Configure terminationGracePeriodSeconds
# ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/
terminationGracePeriodSeconds: 30

# -- Configure lifecycle hooks
# ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/
# lifecycle:
#  postStart:
#    exec:
#      command: ['/bin/sh', '-c', 'echo Called postStart hook > /proc/1/fd/1'],
#  preStop:
#    exec:
#      command: ['/bin/sh', '-c', 'echo Called preStop hook > /proc/1/fd/1'],

# -- Configure extra options for readiness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
readiness:
  enabled: true
  #  methodOverride:
  #    httpGet:
  #      # -- Request path for readinessProbe
  #      path: /readiness
  #      # -- Port for readinessProbe
  #      port: 8000
  #      # -- Scheme (HTTP or HTTPS)
  #      scheme: HTTP
  # -- Path to hit for readiness checks
  #  path: /readiness
  # -- Name of the port to use for readiness checks
  #  port: http
  # -- Scheme (HTTP or HTTPS)
  #  scheme: HTTP
  # -- Initial delay seconds for readinessProbe
  #  initialDelaySeconds: 25
  # -- Period seconds for readinessProbe (frequency)
  #  periodSeconds: 10
  # -- Timeout seconds for readinessProbe
  #  timeoutSeconds: 1
  # -- Failure threshold for readinessProbe
  #  failureThreshold: 2
  # -- Success threshold for readinessProbe
  #  successThreshold: 1

# -- Container resource requests and limits
# ref: http://kubernetes.io/docs/user-guide/compute-resources
resources:
  # -- The resource limits for the container
  limits: {}
  #    cpu: 1000m
  #    memory: 2Gi
  # -- The requested resources for the container
  requests: {}
  #    cpu: 1000m
  #    memory: 1Gi

# -- Prometheus Exporter / Metrics
metrics:
  # -- Enable Prometheus to access aplpication metrics endpoints
  enabled: true
  # -- Interval at which metrics should be scraped
  # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  #  interval: 30s
  # -- URL path to the metrics endpoint
  #  path: /metrics
  # -- Name of the port to use for metrics endpoint
  #  port: http
  # -- Timeout after which the scrape is ended
  # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  #  timeout: 10s
  # -- Scheme (HTTP ot HTTPS)
  #  scheme: HTTP
  basicAuth:
    enabled: false
    secretName: ""
    usernameKey: ""
    passwordKey: ""
  additionalMonitors: []

# -- Define ExternalSecret from AWS
# ref: https://github.com/external-secrets/kubernetes-external-secrets
externalSecret:
  enabled: true
  #  nameOverride: ""
  #  pathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""
  #  localValues:
  #    - name: TEST_SECRET
  #      value: test_value
extraSecrets: []
#  - name: ""
#    pathOverride: ""
#    pathSuffix: ""
#    refreshIntervalOverride: ""
#    secretStoreRefOverride: ""
#    includeInMain: true # defaults to true if not set
#    localValues: []

# -- A list of configuration maps for this application
configMaps: []
#    # -- Name of the config map
#  - name: ""
#    # -- Whether or not to create the configmap
#    create: false
#    # -- List of configs (files) within the configmap
#    configs:
#      - name: ""
#        data: ""

# -- A list of volumes to be added to the pod
volumes:
  #  - configMap:
  #      name: portal-web-something
  #    name: portal-web-something

# -- A list of persistent volume claims to be added to the pod
persistentVolumes:
  #  - name: brms-drools-workbench-niogit
  #    mode: ReadWriteOnce
  #    size: 100Mi

# -- A list of volume mounts to be added to the pod
volumeMounts: []

# -- Configure an NLB to route traffic direct to pods (for non HTTP traffic)
nlb:
  enabled: false
  # -- Public or private nlb (internet-facing / internal)
  scheme: internet-facing
  # -- TargetType {instance = nodePort, ip = podIP}
  targetType: ip
  # -- Configure healthchecks
  healthcheck:
    # -- Healthcheck protocol
    protocol: TCP
    # -- Period seconds {can only be 10 or 30 seconds)
    intervalSeconds: 10
    # -- Healthcheck Request path
    # path: /
    # -- Port (defaults to port specified in Ingress used to direct traffic to service)
    # port: "8000"
    # -- Timeout seconds
    timeoutSeconds: 5
    # -- Failure threshold
    unhealthyThresholdCount: 2
    # -- Success threshold
    healthyThresholdCount: 2

# -- Configure the ingress resource that allows you to access the application from public-internet
# ref: http://kubernetes.io/docs/user-guide/ingress/
ingress:
  # -- Set to true to enable ingress record generation
  enabled: false
  # -- Additional Ingress annotations
  # For a full list of possible ingress annotations, please see
  # ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
  extraAnnotations: {}
  # -- Optional: ability to construct multiple ingresses with different settings (names, cache headers, etc)
  # Should be able to override all Ingress values be setting them again on a per instance basis
  extraIngresses: []
  # -- Explicitly set the 'tier: frontend' label on deployments even if ingress is disabled
  allowFrontendAccess: false
  # -- Only applies for 'haproxy' ingresses; Sets X-Forwarded-For headers
  setXForwardedForHeaders: false
  # -- Only applies for 'haproxy' ingresses; Sets no-cache headers
  setNoCacheHeaders: false
  # -- Enable TLS configuration for the hostname defined at ingress.hostname parameter
  tls: true
  # -- List of extra ingress hosts to setup
  extraHosts: []
  #  extraHosts:
  #    - name: ""
  #      path: ""
  #      pathType: "Prefix"
  #      serviceName: ""
  #      servicePort: ""
  # -- Optional, defines number of seconds to set server-timeout to
  #  serverTimeoutSeconds: 10
  # -- Set to true to allow the liveness URL through the ingress
  allowLivenessUrl: false
  # -- Set to true to allow the readiness URL through the ingress
  allowReadinessUrl: false
  # -- Configures annotations defining blackbox endpoints
  blackbox:
    # -- Set to true to tell blackboxes to hit endpoint
    enabled: true
    # -- Endpoint for blackboxes to hit
    probePath: /external-health-check
  # -- Optional ingress Rules Hosts Yaml that doesn't fit standard pattern
  specificRulesHostsYaml: {}
  # -- Optional ingress Tls Hosts Yaml that doesn't fit standard pattern
  specificTlsHostsYaml: {}
  alb:
    enabled: true
    # -- Public or private alb (internet-facing / internal)
    scheme: internet-facing
    # -- Application Version (HTTP / HTTPS)
    backendProtocol: HTTP
    # -- Application Protocol Version (HTTP1 / HTTP2 / GRPC)
    backendProtocolVersion: HTTP1

    # -- Enable and configure authentication using okta
    # aws-load-balancer-controller must be installed on the cluster for Okta integration to work
    okta:
      enabled: false
      # -- (required) Name of the ingress
      ingressName: ''
      # -- Comma separated list of Okta Users that have access to the Ingress URI. e.g. 'user1,user2,user3'
      users: ''
      # -- Comma separated list of Okta Groups that have access to the Ingress URI. e.g. 'group1,group2,group3'
      groups: ''
      # -- The path that is appended onto the Ingress URI for Oauth authentication on the Ingress URI. Defaults to '/oauth2/idpresponse/'
      redirectPath: ''
      # -- Specifies the behavior if the user is not authenticated.
      #    Possible values are 'authenticate' (defalt value, and used in most cases), 'allow', or 'deny'
      authOnUnauthenticated: 'authenticate'

    deregistrationDelay:
      timeoutSeconds: 5

    preStopDelay:
      # -- Enable an additional delay when the container is shutdown of delaySeconds.
      # This allows ALB to fully de-register the pod (allows zero-downtime rollouts)
      enabled: true
      # -- The delay (sleep) to wait for.
      # IMPORTANT: The terminationGracePeriodSeconds must be greater than this.
      delaySeconds: 15

    healthcheck:
      # -- Healthcheck protocol
      protocol: HTTP
      # -- Healthcheck success codes
      # successCodes: "200"
      # -- Period seconds
      intervalSeconds: 15
      # -- Healthcheck Request path
      # path: /readiness
      # -- Port (defaults to port specified in Ingress used to direct traffic to service)
      # port: "8000"
      # -- Timeout seconds
      timeoutSeconds: 5
      # -- Failure threshold
      unhealthyThresholdCount: 2
      # -- Success threshold
      healthyThresholdCount: 2

# -- If true, use the host network for the main deployment.
useHostNetwork: false

# -- Define a default NetworkPolicy for allowing apps in the same 'app.kubernetes.io/part-of' group to communicate
# with eachother.
# ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
networkPolicy:
  enabled: true
  additionalAllowFroms: []
  #    - fromName: 'brms-bridge'
  #      toName: ''
  #      toPorts: []
  #        - port: 8080
  #          protocol: TCP

# -- Enable extra init-containers
extraInitContainers: []

# -- Enable extraContainers (oauth2-proxy is a common example)
extraContainers: []
# extraContainers:
# - name: oauth2-proxy
#   image: quay.io/oauth2-proxy/oauth2-proxy:v7.1.3
#   ...

# -- Defines deployment update strategy
strategy:
  # -- Type of strategy to use (Recreate or RollingUpdate)
  type: RollingUpdate
  # -- Optional argument to define maximum number of pods allowed over defined replicas
  maxSurge: 15%
  # -- Optional argument to define maximum number of pods that can be unavailable during update
  maxUnavailable: 10%

topologySpreadConstraints:
  enabled: true
  zone:
    enabled: true
    maxSkew: 1
  node:
    # -- Set this to true/false to override the default behaviour (enabled for prod only)
    enabled:
    maxSkew: 1
  # -- Specify custom topologySpreadConstraints yaml
  specificYaml:

# -- Configure the deployment affinity/anti-affinity rules
# ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
affinity:
  # -- Set to true to enable deployment affinity rules
  enabled: false
  # -- Configure pod anti-affinity rules
  podAntiAffinity:
    # -- Toggle whether zone affinity should be required (hard) or preferred (soft)
    zone: hard
    # -- Toggle whether node affinity should be required (hard) or preferred (soft)
    node: soft
    # -- Optional weight to apply to soft affinity
    #    weight: 200
  # -- Specify custom affinity yaml
  #  specificYaml:
  #    podAntiAffinity:
  #      preferredDuringSchedulingIgnoredDuringExecution:
  #      - podAffinityTerm:
  #          labelSelector:
  #            matchExpressions:
  #            - key: app.kubernetes.io/name
  #              operator: In
  #              values:
  #              - portal-web
  #          topologyKey: topology.kubernetes.io/zone
  #        weight: 100

# -- Configure connection to the Event Bus
eventBus:
  # -- Set to true to set Event Bus environment variables
  enabled: false
  # -- Required: AWS account ID where the Event Bus is located
  accountId: ""
  # -- Whether or not app is considered interactive
  interactiveApp: false
  # -- Max number of workers
  maxWorkers: 1
  # -- AWS region where Event Bus is located
  region: "us-east-2"
  # -- Required: Which service to use
  serviceName: ""

# -- Configure oauth-proxy sidecar for main deployment
oauthProxy:
  # -- Set to true to enable oauth-proxy sidecar
  enabled: false
  # -- Full image name override
  image: "quay.io/oauth2-proxy/oauth2-proxy:v7.1.3"
  # -- Optional: hostname for proxy redirect url (defaults to service defaultHost)
  ingressHost: ""
  # -- Optional: URL of the OIDC issuer
  issuerUrl: "https://oauth.mintel.com"
  # -- Optional: email domain to restrict access to
  emailDomain: ""
  # -- Optional: list of group ids to restrict access to
  allowedGroups: []
  # -- Identifies oauth-proxy as auth'ing with a mintel portal instance
  type: portal
  # -- Optional: OAuth scope specification
  scope: "openid profile email"
  # -- Optional: oauth secret suffix, eg '-oauth'
  secretSuffix: ""
  # -- Optional: full name override for oauth secret
  secretNameOverride: ""
  # -- Optional: ExternalSecret refreshInterval override
  secretRefreshIntervalOverride: ""
  # -- Optional: full SecretStoreRef override for oauth ExternalSecret
  secretStoreRefOverride: ""
  # -- Optional: list of URL endpoints to bypass oauth-proxy for
  # Health check and readiness urls are skipped automatically
  skipAuthRegexes: []
  # -- Container resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources
  #  resources:
  # -- The resource limits for the container
  #    limits: {}
  #    cpu: 200m
  #    memory: 128Mi
  # -- The requested resources for the container
  #    requests: {}
  #    cpu: 100m
  #    memory: 64Mi
  #
  #
  # -- Optional: Claim contains the user ID
  userIdClaim: ""
  # -- Optional environment variables injected into the container
  env: []
  #    - name: OAUTH_PROXY_SKIP_AUTH_PREFLIGHT
  #      value: true
  localSecretValues: []
  #    - name: OAUTH_PROXY_CLIENT_ID
  #      value: test_value
  #    - name: OAUTH_PROXY_CLIENT_SECRET
  #      value: test_value
  #    - name: OAUTH_PROXY_COOKIE_SECRET
  #      value: test_value

# -- Configure the use of kubelock
# ref: https://github.com/mintel/kubelock
kubelock:
  # -- Set to true to enable kubelock
  enabled: false
  #  nameOverride: ""

# -- Configure Consul annotations to the main deployment for hybrid cloud integration
hybridCloud:
  # -- Set to true to integrate with hybrid cloud (Consul)
  enabled: false
  # -- Defines list of upstream services to connect to
  #  upstreamServices:
  #    - 'service1:1234'
  #    - 'service2:2345'
  upstreamServices: []
  # -- Configure metrics scraping of Consul Proxy
  metrics:
    # -- Enable Prometheus to scrape consul proxy metrics
    enabled: true
    # -- Interval at which metrics should be scraped
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    #  interval: 30s
    # -- URL path to the metrics endpoint
    #  path: /metrics
    # -- Name of the port to use for metrics endpoint
    #  port: consul-metrics
    # -- Timeout after which the scrape is ended
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    #  timeout: 10s
    # -- Scheme (HTTP ot HTTPS)
    #  scheme: HTTP

  # -- Set port for Envoy proxy public listener
  # (the port consul talks back to envoy on)
  proxyPort: 20000
  # -- Define namespace that Consul is runnign in
  consulNamespace: hybrid-consul

# -- Configure celery deployment
# Defaults to same image as main deployment but with the "celery" argument
celery:
  # -- Set to true to enable a celery deployment
  enabled: false
  # -- Desired number of replicas for celery deployment
  replicas: 2
  # -- Full image name override (registry/repository:tag)
  #  image: ""
  # -- Optional command to the celery container
  #  command: []
  # -- Arguments to the celery container
  args:
    - "celery"
  # -- Optional environment variables injected into the container
  #  env: []
  # -- Container resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources
  resources:
    # -- The resource limits for the container
    limits: {}
    #    cpu: 1000m
    #    memory: 2Gi
    # -- The requested resources for the container
    requests: {}
    #    cpu: 1000m
    #    memory: 2Gi
  # -- Configure extra options for liveness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  liveness:
    # -- Enable liveness probe
    enabled: false

  # -- Configure extra options for the start-up probe that is enabled when celery.liveness.enabled is set to true
  startup:
    # -- Allows a non-default startup probe implementation
    methodOverride: {}
    # -- The number of times the start-up probe is allowed to fail before the pod is deemed to have failed to start.
    failureThreshold: 60
    # -- The period of time to wait for an individual run of the start-up check to complete.
    periodSeconds: 5
    # -- Timeout seconds for startupProbe
    #  timeoutSeconds: 1
  # -- Configure extra options for readiness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  readiness:
    # -- Enable readiness probe
    enabled: false
  # -- Prometheus Exporter / Metrics
  metrics:
    # -- Enable Prometheus to access application metrics endpoints
    enabled: true
    # -- Port to collect celery metrics
    port: metrics
  # -- Pod Disruption Budget
  # ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    enabled: true
    minAvailable: 50%

# -- Configure celerybeat deployment
# Defaults to same image as main deployment but with the "celerybeat" argument
celeryBeat:
  # -- Set to true to enable a celerybeat deployment
  enabled: false
  # -- Full image name override (registry/repository:tag)
  #  image: ""
  # -- Optional command to the celery container
  #  command: []
  args:
    - "celerybeat"
  # -- Optional environment variables injected into the container
  #  env: []
  # -- Container resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources
  resources:
    # -- The resource limits for the container
    limits: {}
    #    cpu: 1000m
    #    memory: 2Gi
    # -- The requested resources for the container
    requests: {}
    #    cpu: 1000m
    #    memory: 2Gi
  # -- Configure extra options for liveness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  liveness:
    # -- Enable liveness probe
    enabled: false
  # -- Configure extra options for readiness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  readiness:
    # -- Enable readiness probe
    enabled: false

# -- Only show cronjobs and relevant resources (i.e. if set to `true`, hide the main deployment resource)
cronjobsOnly: false

# -- Define and Configure CronJob's
# Defaults to same image as main deployment but with defined arguments
cronjobs:
  # -- Defaults for all CronJob's
  defaults:
    # -- Tells controller to suspend future executions
    # ref: https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/cron-job-v1/#CronJobSpec
    suspend: false
    # -- Tells controller how to handle concurrent executions of a CronJob
    # ref: https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/cron-job-v1/#CronJobSpec
    concurrencyPolicy: Forbid
    # -- Configure CronJob pod restart Policy
    # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
    restartPolicy: Never
  # -- List of Cronjob configurations to be defined
  jobs:
    []
    # - name: 'daily'
    #   concurrencyPolicy: Forbid
    #   suspend: false
    #   restartPolicy: Never
    #   schedule: "0 0 * * *"
    #   image: ''
    #   command:
    #     - '/bin/sh'
    #   args:
    #     - '-c'
    #     - 'NO_MIGRATE=1'
    #     - '/app/docker-entrypoint.sh'
    #     - 'manage'
    #     - 'daily'
    #   env: []
    #   envFrom: {}
    #   podSecurityContext:
    #     runAsUser: 1000
    #   extraInitContainers: {}
    #   resources:
    #     limits:
    #       cpu: 1000m
    #       memory: 2Gi
    #     requests:
    #       cpu: 1000m
    #       memory: 2Gi
    #   includeBaseEnv: false
    #   includeMailhogEnv: false
    #   includeRedisEnv: false
    #   includeElasticsearchEnv: false
    #   includeOpensearchEnv: false
    #   includeLocalstackEnv: false
    #   includeEventBusEnv: false
    #   includeAppSecret: false
    #   includeMariadbSecret: false
    #   includePostgresqlSecret: false
    #   includeElasticsearchSecret: false
    #   includeOpensearchSecret: false

# -- Define and Configure Job's
# Each job has the following configuration options, and defaults to the values below if not set.
jobs:
  []
  #     # The name of the job. Required.
  # - name: ''
  #   argo:
  #       # Phase ArgoCD should apply the manifest, such as PreSync, Sync, PostSync.
  #       # See https://argo-cd.readthedocs.io/en/stable/user-guide/resource_hooks/#usage.
  #     hook: 'Sync'
  #       # When to delete the hook in an automated fashion, suck as HookSucceeded, HookFailed, etc.
  #       # See https://argo-cd.readthedocs.io/en/stable/user-guide/resource_hooks/#hook-deletion-policies.
  #     hookDeletePolicy: 'BeforeHookCreation'
  #       # Order ArgoCD should apply the manifest. Lower values are applied first, and negative values are allowed.
  #       # See https://argo-cd.readthedocs.io/en/stable/user-guide/sync-waves/.
  #     syncWave: '0'
  #     # Whether the pod should be restarted on failure.
  #     # See https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy.
  #   restartPolicy: Never
  #     # Configuration for the job image, command, arguments, environment variables, resources, etc. `resources` is required.
  #   image: '${.image.registry + "/" + .image.repository + ":" + .image.tag}'
  #   command:
  #     - ''
  #   args:
  #     - ''
  #   env: if includeBaseEnv then '${.env}' else []
  #   envFrom: if includeAppSecret then '${.envFrom}' else []
  #   podSecurityContext:
  #     runAsUser: if includeBasePodSecurityContext then '${podSecurityContext.rusAsUser}' else ''
  #   extraInitContainers: []
  #   resources: []
  #     # Whether to use the main deployment values above
  #   includeBaseEnv: false
  #   includeAppSecret: false
  #   includeBasePodSecurityContext: false

dynamodb:
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""
  #  secretPathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""

mariadb:
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""
  #  secretPathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""
  #  auth:
  #    database: ""
  #    username: ""
  #    password: ""
  client:
    enabled: true
    #    image: {}
    resources:
      limits:
        cpu: 300m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 64Mi
  metrics:
    enabled: false
    #    image: {}
    resources:
      limits:
        cpu: 300m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 64Mi

postgresql:
  enabled: false
  postgresqlDatabase: "postgres"
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""
  #  secretPathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""
  #  auth:
  #    database: ""
  #    username: ""
  #    password: ""
  #    port: "5432"
  image:
    tag: "13.5.0-debian-10-r52"
  client:
    enabled: true
    #    image: {}
    resources:
      limits:
        cpu: 300m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 64Mi
  metrics:
    enabled: false
    #    image: {}
    resources:
      limits:
        cpu: 300m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 64Mi

redis:
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""
  #  secretPathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""
  replica:
    replicaCount: 0
  tls:
    enabled: false

s3:
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""
  #  secretPathOverride: ""
  #  secretRefreshIntervalOverride: ""
  #  secretStoreRefOverride: ""

sqs:
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  #  secretNameOverride: ""

# -- Helper to sync a local directory with Git
# ref: https://github.com/kubernetes/git-sync
gitSyncSidecar:
  enabled: false

  # -- The git repository to clone
  # repo: <your-git-repo>

  # -- The git branch to check out
  branch: main

  # -- The root directory for git-sync operations, under which --dest will be created
  root: /data/git-sync

  # -- The name of (a symlink to) a directory in which to check-out files under --root
  #  dest: <your-dest>

  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 50m
      memory: 50Mi

filebeatSidecar:
  enabled: false
  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi
      #  configmap:
      #    - name: "filebeat.yml"
      #      data: |
      #        http.enabled: true
      #        http.host: '0.0.0.0'
      #    - name: "portal-usage-ilm.json"
      #      data: "json1"
      #    - name: "portal-usage-template.json"
      #      data: "json2"
  metrics:
    enabled: true
    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

mailhog:
  enabled: false

kibana:
  enabled: false
  elasticsearchHosts: ""

elasticsearch:
  enabled: false
  # -- Optional: ExternalSecret refreshInterval override
  secretRefreshIntervalOverride: ""
  # -- Optional: override the SecretStoreRef of the ExternalSecret
  secretStoreRefOverride: ""

# -- Configures AWS Opensearch deployment/connections
opensearch:
  # -- Set to true if deployment makes use of AWS opensearch
  enabled: false
  # -- set outputSecret to true to allow TF Cloud chart create ExternalSecrets
  outputSecret: true
  # -- Configures aws-es-proxy to enable external access to opensearch
  awsEsProxy:
    # -- Set to true to add an aws-es-proxy deployment in front of opensearch
    enabled: false
    # -- Container resource requests and limits for aws-es-proxy sidecar
    # ref: http://kubernetes.io/docs/user-guide/compute-resources
    resources:
      limits:
        cpu: 200m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 64Mi
    # -- Port for aws-es-proxy to listen on
    port: 9200
    # -- Ingress for aws-es-proxy
    ingress:
      enabled: false
      # -- Path for the Ingress
      path: /_dashboards
      extraAnnotations: {}
      alb:
        enabled: true
        # -- Public or private alb (internet-facing / internal)
        scheme: internet-facing
        # -- Application Version (HTTP / HTTPS)
        backendProtocol: HTTP
        # -- Application Protocol Version (HTTP1 / HTTP2 / GRPC)
        backendProtocolVersion: HTTP1

        # -- Enable and configure authentication using okta
        # aws-load-balancer-controller must be installed on the cluster for Okta integration to work
        okta:
          enabled: false
          # -- (required) Name of the ingress
          ingressName: ''
          # -- Comma separated list of Okta Users that have access to the Ingress URI. e.g. 'user1,user2,user3'
          users: ''
          # -- Comma separated list of Okta Groups that have access to the Ingress URI. e.g. 'group1,group2,group3'
          groups: ''
          # -- The path that is appended onto the Ingress URI for Oauth authentication on the Ingress URI. Defaults to '/oauth2/idpresponse/'
          redirectPath: ''
          # -- Specifies the behavior if the user is not authenticated.
          #    Possible values are 'authenticate' (defalt value, and used in most cases), 'allow', or 'deny'
          authOnUnauthenticated: 'authenticate'

        deregistrationDelay:
          timeoutSeconds: 5

        preStopDelay:
          # -- Enable an additional delay when the container is shutdown of delaySeconds.
          # This allows ALB to fully de-register the pod (allows zero-downtime rollouts)
          enabled: true
          # -- The delay (sleep) to wait for.
          # IMPORTANT: The terminationGracePeriodSeconds must be greater than this.
          delaySeconds: 15

        healthcheck:
          # -- Healthcheck protocol
          protocol: HTTP
          # -- Healthcheck success codes
          # successCodes: "200"
          # -- Period seconds
          intervalSeconds: 15
          # -- Healthcheck Request path
          path: /_cluster/health
          # -- Port (defaults to port specified in Ingress used to direct traffic to service)
          # port: "9200"
          # -- Timeout seconds
          timeoutSeconds: 5
          # -- Failure threshold
          unhealthyThresholdCount: 2
          # -- Success threshold
          healthyThresholdCount: 2
  # -- Optional: ExternalSecret refreshInterval override
  secretRefreshIntervalOverride: ""
  # -- Optional: override the SecretStoreRef of the ExternalSecret
  secretStoreRefOverride: ""

localstack:
  enabled: false
  startServices: "sns, sqs, s3"
  enableStartupScripts: true
  service:
    type: ClusterIP
  mountDind:
    enabled: true
  extraEnvVars:
    - name: AWS_DEFAULT_REGION
      value: us-east-1
    - name: AWS_ACCESS_KEY_ID
      value: test
    - name: AWS_SECRET_ACCESS_KEY
      value: test

# -- Configuration for creating a VerticalPodAutoscaler for this app. Currently only supports recommendations-only mode.
verticalPodAutoscaler:
  # -- Set to true to create a VerticalPodAutoscaler.
  enabled: true
